{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Correlation between Supershop Sales and Weather Patterns in Myanmar (Yangon, Mandalay, Naypyitaw): A Data-Driven Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, sys, re\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    connection = sqlite3.connect(\"../data/analysis.sqlite\")\n",
    "    weather = pd.read_sql_query(f\"SELECT * FROM weather\", connection)\n",
    "    supermarket_sales = pd.read_sql_query(f\"SELECT * FROM supermarket_sales \", connection)    \n",
    "except sqlite3.Error as e:\n",
    "    logging.error(msg=f\"Error while creating SQLite DB: {e}\")\n",
    "    sys.exit(1)\n",
    "finally:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>City_x</th>\n",
       "      <th>City_y</th>\n",
       "      <th>Product line</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total</th>\n",
       "      <th>Payment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Tavg, Tmin, Tmax, City_x, City_y, Product line, Quantity, Total, Payment]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.merge(weather,supermarket_sales,on= \"Date\")\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "\n",
    "The retail industry, particularly supermarkets, is heavily influenced by external factors such as weather conditions. Understanding the relationship between weather patterns and Supershop sales is crucial for optimizing inventory management, pricing strategies, and marketing efforts. This project aims to explore the impact of weather on Supershop sales in three major cities in Myanmar: Yangon, Mandalay, and Naypyitaw. The significance of understanding this correlation lies in its potential to revolutionize conventional strategies related to inventory management, pricing dynamics, and targeted marketing initiatives. By unraveling the interplay between weather nuances and purchasing trends, businesses can harness the power of predictive analytics to anticipate and respond to fluctuations in demand effectively. \n",
    "\n",
    "#### 1.1 Project Goals \n",
    "The question that interests us is: How do the weather conditions in these cities impact the supermarket sales? And we will try to answer this question by focusing on several short questions.\n",
    "\n",
    "1. How does the temperature in Yangon cities vary Jan to March in year 2019?\n",
    "2. How does the temperature in Mandalay cities vary Jan to March in year 2019?\n",
    "3. How does the temperature in Naypyitaw cities vary Jan to March in year 2019?\n",
    "4. How does the supermarket sales in those cities vary during the exact time frame?\n",
    "5. Does temperature affect supermaket sales in Yangon, Mandalay, and Naypyitaw city?\n",
    "\n",
    "The subsequent sections of this report are structured as follows: Section 2 provides a comprehensive overview and analysis of the datasets. Following this, Section 3 elucidates the adopted methodology. Subsequently, Section 4 encompasses the presentation of the project's results. Finally, Section 5 comprises discussions, and remarks, and outlines avenues for future work in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Sources:\n",
    "To accomplish the project goals, two datasets were required. After a thorough investigation, I came across two sources online that meets the project requirements, namely Kaggle and Meteostat. I will briefly explain the datasets in below sections,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Supermarket Sales Data:\n",
    "This dataset provides daily sales information from Supershops in the specified cities, offering a comprehensive view of sales trends for Yangon, Mandalay, and Naypyitaw city. It is a very popular open-source dataset, I have collected it from Kaggle. The Table 1 contains the column names and descriptions of the supermaket sales dataset. \n",
    "         \n",
    "* Metadata URL: https://www.kaggle.com/datasets/aungpyaeap/supermarket-sales/data\n",
    "* Data URL: https://www.kaggle.com/datasets/aungpyaeap/supermarket-sales/download?datasetVersionNumber=3\n",
    "* Data Type: CSV\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> Column index</th>\n",
    "        <th> Column name </th>\n",
    "        <th> Description </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 0 </td> \n",
    "        <td> Invoice id </td> \n",
    "        <td> Invoice identification number </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 1 </td>\n",
    "        <td> Branch </td>\n",
    "        <td> Branch (3 branches available: A, B and C) </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 2 </td>\n",
    "        <td> City </td>\n",
    "        <td> City name </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 3 </td>\n",
    "        <td> Customer type </td>\n",
    "        <td> Type of customers. </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 4 </td> \n",
    "        <td> Gender </td>\n",
    "        <td> Gender </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 5 </td> \n",
    "        <td> Product line </td> \n",
    "        <td> General item categorization groups  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 6 </td> \n",
    "        <td> Unit price </td> \n",
    "        <td> Price of each product in \\$ </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 7 </td> \n",
    "        <td> Quantity </td> \n",
    "        <td> Number of products purchased  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 8 </td> \n",
    "        <td> Tax </td>\n",
    "        <td> 5\\% tax fee for customer buying  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 9 </td> \n",
    "        <td> Total </td>\n",
    "        <td> Total price including tax </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 10 </td> \n",
    "        <td> Date </td> \n",
    "        <td> Date of purchase (Record available from January 2019 to March 2019)  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 11 </td> \n",
    "        <td> Time </td> \n",
    "        <td> Purchase time (10am to 9pm) </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 12 </td> \n",
    "        <td> Payment </td> \n",
    "        <td> Payment type  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 13 </td> \n",
    "        <td> COGS </td> \n",
    "        <td> Cost of goods sold </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 14 </td> \n",
    "        <td> Gross margin percentage </td> \n",
    "        <td> Gross margin percentage </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 15 </td> \n",
    "        <td> Gross income </td>\n",
    "        <td> Gross income </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 16 </td> \n",
    "        <td> Rating </td> \n",
    "        <td> Customer stratification rating (On a scale of 1 to 10) </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "    <caption>Table 1: Daily super market sales dataset.</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Weather Data:\n",
    "Weather data includes factors like temperature, humidity, wind speed, and precipitation. Obtained from Meteostat, this data aims to capture the meteorological conditions in Yangon, Mandalay, and Naypyitaw city. The Table 2 contains the column names and descriptions of the weather data.\n",
    "\n",
    "* Metadata URL: https://dev.meteostat.net/bulk/daily.html\n",
    "* Data URL: https://bulk.meteostat.net/v2/daily/{station_id}.csv.gz ; station_id = 48097, 48042, VYNT0\n",
    "* Data Type: CSV\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> Column index</th>\n",
    "        <th> Column name </th>\n",
    "        <th> Description </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 0 </td> \n",
    "        <td> Date </td> \n",
    "        <td> The Date string (format: YYYY-MM-DD) </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 1 </td>\n",
    "        <td> Tavg </td>\n",
    "        <td> The average air temperature in °C </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 2 </td>\n",
    "        <td> Tmin </td>\n",
    "        <td> The minimum air temperature in °C </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 3 </td>\n",
    "        <td> Tmax </td>\n",
    "        <td> The maximum air temperature in °C </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 4 </td> \n",
    "        <td> Prcp </td>\n",
    "        <td> The daily precipitation total in mm </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 5 </td> \n",
    "        <td> Snow </td> \n",
    "        <td> The maximum snow depth in mm </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 6 </td> \n",
    "        <td> Wdir </td> \n",
    "        <td> The average wind direction in degrees (°) </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 7 </td> \n",
    "        <td> Wspd </td> \n",
    "        <td> The average wind speed in km/h  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 8 </td> \n",
    "        <td> Wpgt </td>\n",
    "        <td> The peak wind gust in km/h  </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 9 </td> \n",
    "        <td> Pres </td>\n",
    "        <td> The average sea-level air pressure in hPa </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> 10 </td> \n",
    "        <td> Tsun </td> \n",
    "        <td> The daily sunshine total in minutes (m)  </td> \n",
    "    </tr>\n",
    "    <caption>Table 2: Summery of Yagon, Mandalay, Naypyitaw dataset.</caption>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Methodology\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"images/Methodology.jpeg\" style=\"width:60%\">\n",
    "    <figcaption align=\"center\"> Figure 1: Methodology </figcaption>\n",
    "</figure>\n",
    "\n",
    "The following is a more detailed step-by-step description of the process:\n",
    "\n",
    "Step 1: Run the ETL Pipelines and load the data into a SQLite database.\n",
    "\n",
    "Step 2: Analyse the Naypyitaw, Mandaley, and Yagon city's weather and find how the temparature vary during Jan to March, 2019. \n",
    "\n",
    "Step 3: Analyse the Naypyitaw, Mandaley, and Yagon city's supershops sales and find out how the sales vary in those cities during the exact time frame.\n",
    "\n",
    "Step 4: Run a Combined Analysis on Supershop sales and weather to find if there are any relationship between sales and temparature.\n",
    "\n",
    "Step 5: Get the output. \n",
    "\n",
    "Figure 1 illustrates the project's methodology.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Extract Transform Load (ETL) Pipeline:\n",
    "\n",
    "The implementation of the ETL pipeline, depicted in Figure 2, played a pivotal role in this project. Raw data extraction from various sources marked the initial phase, followed by a series of cleaning processes detailed in Section 3.2. After transformation the refined data found its repository in a SQLite database for subsequent analysis. Notably, the utilization of a queue proved essential, particularly in consolidating weather data from multiple cities into a single table.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"images/ETL_pipeline.jpeg\" style=\"width:100%\">\n",
    "    <figcaption align=\"center\"> Figure 2: ETL Pipeline structure </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Data Cleaning/Transformation:\n",
    "\n",
    "Both datasets underwent various transformations to enhance their relevance to the project. For the Supermarket sales dataset, non-essential columns \"Invoice ID\", \"Branch\", \"Customer type\", \"Gender\", \"Unit price\", \"Tax 5%\", \"Time\", \"cogs\", \"gross margin percentage\", \"gross income\", and \"Rating\"  were removed. \n",
    "\n",
    "As for the weather data, there were three city-specific datasets and I had to consolidated into one table. So, I have added a new column named \"City\". Subsequently, irrelevant columns \"Prcp\", \"Snow\", \"Wdir\", \"Wspd\", \"Wpgt\", \"Pres\", and \"Tsun\" were dropped. \n",
    "\n",
    "The final database comprises two tables: weather and supermarket_sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Challenges Encountered:\n",
    "\n",
    "Throughout the course of this project, I have encountered various challenges, with one particularly noteworthy obstacle involving the identification of appropriate datasets that aligned with the project's specific requirements. Navigating the online landscape, I discovered that not all datasets were open source or directly relevant to our project topic. Numerous revisions were necessary to go through available options and ultimately select datasets that met the criterias.\n",
    "\n",
    "Additionally, I have faced the challenge of collecting weather data for three distinct cities and combined them into a cohesive dataset in real-time within our pipeline. To tackle this hurdle, I implemented a pipeline queue to meticulously execute the extraction, transformation, and loading processes for weather data in a sequential manner. This strategic approach allowed to address the complexities associated with combining data from multiple sources and ensured the seamless integration of weather information from the specified cities during the runtime of our project pipeline. \n",
    "\n",
    "Lastly, while merging the dataset on \"Date\" I found the date format was not same. Therefore, I had to make the date format identical for both datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Python pakage to run ETL pipeline \n",
    "Inspired by Jayvee, my coursemate Badiuzzaman Pranto, and I collaborated on the development of an open-source [Python package](https://github.com/prantoamt/etl-pipeline-runner) throughout our coursework. Our individual projects in this course had distinct objectives,resulting in the creation of ETL pipelines with varying structures.In my project, the challenge revolved around extracting data from a source providing direct CSV files, accompanied by unique set of transformations, and subsequently loading it into the database. On the other hand, Pranto’s project centered extracting data from Kaggle archives. Recognizing these are foundational requirements for any data science project, we deliberately structured our code in a generic manner, giving rise to the inception of this reusable Python package.\n",
    "\n",
    "##### 3.4.1 Features as of version 1.1.0:\n",
    "\n",
    "1. Data Extraction Capabilities:\n",
    "\n",
    "- Extract data from Kaggle (Contributed by Pranto).\n",
    "\n",
    "- Extract data directly from sources providing CSV files (Contributed by me).\n",
    "\n",
    "- Handle CSV files seamlessly (Joint contribution).\n",
    "\n",
    "2. Data Transformation and Loading:\n",
    "\n",
    "- Perform project-specific transformations with flexibility (Joint contribution).\n",
    "\n",
    "- Load data efficiently into SQLite databases (Joint contribution).\n",
    "\n",
    "3. Pipeline Management:\n",
    "\n",
    "- Run multiple pipelines in a queue for streamlined execution (Joint contribution).\n",
    "\n",
    "##### 3.4.2 Possible features for future:\n",
    "\n",
    "1. Expand Data Source Compatibility:\n",
    "\n",
    "- Enhance data extraction capabilities by allowing archives to be extracted from sources other than Kaggle.\n",
    "\n",
    "2. Database Interaction:\n",
    "\n",
    "- Enable data extraction directly from databases, broadening the scope of data sources.\n",
    "\n",
    "3. File Format Compatibility:\n",
    "\n",
    "- Handle XL/XLS files to accommodate a wider range of data formats.\n",
    "\n",
    "4. Database Flexibility:\n",
    "\n",
    "- Extend data loading capabilities to support other types of databases.\n",
    "\n",
    "5. Parallel execution:\n",
    "\n",
    "- Execute multiple pipelines concurrently.\n",
    "\n",
    "**You are warmly invited to submit feature requests, actively contribute to the package’s development, and collec-tively address the evolving needs of the data science community.**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Temparature variation of Yangon city from Jan to March 2019: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Supershop Sells variation of Yangon city Jan to march 2019:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Temparature variation of Mandalay city from Jan to March 2019: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Supershop Sells variation of Mandalay city Jan to march 2019:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Temparature variation of Naypyitaw city from Jan to March 2019: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Supershop Sells variation of Naypyitaw city Jan to march 2019:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Realationship between temparature and supershop sells in those cities during the exact time frame: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion/Conclusions: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Results:\n",
    "\n",
    "Upon analysis, a clear correlation emerges between certain meteorological factors and air quality. For example, elevated temperatures and stagnant wind conditions coincide with higher pollutant concentrations. Additionally, specific areas within the city exhibit consistently poorer air quality, suggesting localized sources of pollution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations:\n",
    "\n",
    "Despite the thorough data engineering process, limitations exist. The spatial density of monitoring stations may lead to data gaps in certain regions. The absence of real-time data poses challenges in capturing dynamic pollution events. Additionally, the complexity of urban environments introduces confounding factors that may not be fully accounted for in this analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
